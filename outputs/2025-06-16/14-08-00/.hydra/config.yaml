seed: 42
checkpoint_dir: adapter
experiment_name: ${models}_eval
logger:
  wandb_mode: disabled
  project: ensamble-semantic-uncertainty
  entity: keram
  log_model: false
  logging_steps: 10
  report_to: wandb
generation:
  num_few_shot: 10
  brief_response: true
  brief_prompt: 'Answer the following question in a single brief but complete sentence.

    '
  use_context: true
  append_answer: true
  seed: ${seed}
models:
  llama3:
    name: llama
    version: 3.2
    size: 1B
    model_name: meta-llama/Llama-3.2-1B
    model_it_name: meta-llama/Llama-3.2-1B-Instruct
    model_spec:
      _target_: transformers.AutoModelForCausalLM.from_pretrained
      pretrained_model_name_or_path: ${models.llama3.model_name}
    tokenizer_spec:
      _target_: transformers.AutoTokenizer.from_pretrained
      pretrained_model_name_or_path: ${models.llama3.model_name}
  llama3_second_instance:
    name: llama
    version: 3.2
    size: 1B
    model_name: meta-llama/Llama-3.2-1B
    model_it_name: meta-llama/Llama-3.2-1B-Instruct
    model_spec:
      _target_: transformers.AutoModelForCausalLM.from_pretrained
      pretrained_model_name_or_path: ${models.llama3.model_name}
    tokenizer_spec:
      _target_: transformers.AutoTokenizer.from_pretrained
      pretrained_model_name_or_path: ${models.llama3.model_name}
dataset:
  name: squad_v2
  huggingface_dataset_id: squad_v2
  spec:
    _target_: datasets.load_dataset
    path: ${dataset.huggingface_dataset_id}
